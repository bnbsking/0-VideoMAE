{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "frequent-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:01:27.50 02624 00:01:27.47\n",
      "0.9404 0.9404\n"
     ]
    }
   ],
   "source": [
    "import json, os, re, math, random\n",
    "import pandas as pd\n",
    "\n",
    "def time2frame(time, fps=30, frameFreq=4):\n",
    "    h, m, s = time.split(\":\")\n",
    "    frame = ( int(h)*3600 + int(m)*60 + float(s)*1 )*fps\n",
    "    frame = str(int( frame//frameFreq*frameFreq + (frame%frameFreq>=frameFreq/2)*frameFreq ))\n",
    "    return \"0\"*(5-len(frame)) + frame\n",
    "\n",
    "def frame2time(frame, fps=30):\n",
    "    frame = int(frame)/fps\n",
    "    h, frame = str(int(frame//3600)), frame%3600\n",
    "    m, s = str(int(frame//60)), round(frame%60,2)\n",
    "    return f\"{ '0'*(2-len(h)) + h }:{ '0'*(2-len(m))+m }:{ '0'*(float(s)<10) + str(s) }\"\n",
    "\n",
    "print(\"00:01:27.50\", time2frameStr(\"00:01:27.50\"), frameStr2time(\"02624\"))\n",
    "\n",
    "entropy = lambda L: round(sum( -x*math.log(x) if x>0 else 0 for x in L ),4)\n",
    "def thresholdConversion(minThreshold, numClass):\n",
    "    return entropy( [minThreshold]+[(1-minThreshold)/(numClass-1)]*(numClass-1) )\n",
    "\n",
    "print( entropy([0.7,0.1,0.1,0.1]), thresholdConversion(0.7,4) )\n",
    "\n",
    "class UnlabeledResult: # Active learning\n",
    "    def __init__(self, testCsvPath, resultFolder, minThreshold=0.7): # pd_cls=class-1=others if max(confidence)<minThreshold (i.e. entropy<self.entropyThreshold)\n",
    "        # load: test.csv, result.json\n",
    "        self.df = pd.read_csv(testCsvPath, header=None, delimiter=' ')[[0]].rename(columns={0:\"imgPath\"})\n",
    "        resultL = json.load(open(f\"{resultFolder}/result.json\",'r')) # shape=(data,classes)\n",
    "        self.entropyThreshold = thresholdConversion(minThreshold, len(resultL[0]))\n",
    "        \n",
    "        # add columns: confidence of each class, entropy, pd_cls\n",
    "        for j in range(len(resultL[0])):\n",
    "            self.df[f\"cf_{j}\"] = [ row[j] for row in resultL ]\n",
    "        self.df[\"entropy\"] = [ entropy(row) for row in resultL ]\n",
    "        self.df[\"pd_cls\" ] = [ row.index(max(row)) if entropy<self.entropyThreshold else len(resultL[0])-1 for row,entropy in zip(resultL,self.df['entropy']) ]\n",
    "        print( self.df['pd_cls'].value_counts() )\n",
    "        \n",
    "        # save: result\n",
    "        self.df.to_csv(f\"{resultFolder}/result.csv\", index=False) # ['imgPath', 'cf_0', 'cf_1', 'cf_2', 'cf_3', 'entropy', 'pd_cls']\n",
    "        self.resultFolder = resultFolder\n",
    "    \n",
    "    def activeEntropy(self, maxN=30):\n",
    "        df_entropy         = self.df[ self.df['entropy']>self.entropyThreshold ][['imgPath','entropy']].sort_values(['entropy'], ascending=False).iloc[:maxN]\n",
    "        df_entropy['time'] = df_entropy['imgPath'].apply(lambda s: frame2time(s[-9:-4]) )\n",
    "        df_entropy['gt']   = [None]*len(df_entropy)\n",
    "        df_entropy.sort_values(['imgPath']).to_csv( f\"{self.resultFolder}/active_entropy.csv\", index=False ) # ['imgPath','entropy','time','gt']\n",
    "        \n",
    "    def activeSeries(self, maxN=30):\n",
    "        classN         = len(self.df.columns)-3\n",
    "        df_series      = self.df[ self.df['pd_cls']!=classN-1 ][['imgPath','pd_cls']].reset_index(drop=True)#; self.df_series=df_series\n",
    "        prev_cls, idxL = df_series['pd_cls'][0], []\n",
    "        for i,pd_cls in enumerate(df_series['pd_cls']):\n",
    "            if pd_cls not in [prev_cls, (prev_cls+1)%(classN-1)]:\n",
    "                idxL.append(i)\n",
    "            prev_cls = pd_cls\n",
    "        print( f\"len(df_series)={len(df_series)}, len(idxL)={len(idxL)}, regular_accuracy={round(1-len(idxL)/len(df_series),3)}\" )\n",
    "        df_series         = df_series.loc[ random.Random(7).sample(idxL,maxN) ]\n",
    "        df_series['time'] = df_series['imgPath'].apply( lambda s: frame2time(s[-9:-4]) )\n",
    "        df_series['gt']   = [None]*len(df_series)\n",
    "        df_series.sort_values(['imgPath']).to_csv( f\"{self.resultFolder}/active_series.csv\", index=False ) # ['imgPath','pd_cls','time','gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "detailed-campbell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    57239\n",
      "2     2879\n",
      "1     2853\n",
      "0     1209\n",
      "Name: pd_cls, dtype: int64\n",
      "len(df_series)=6941, len(idxL)=852, regular_accuracy=0.877\n"
     ]
    }
   ],
   "source": [
    "obj = UnlabeledResult(testCsvPath=\"../_data/csvUnlabeled/20220826_all/test.csv\", resultFolder=\"../_exps/unlabeled_0826_all\")\n",
    "obj.activeEntropy()\n",
    "obj.activeSeries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "liked-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = \"/home/jovyan/data-vol-1/VideoMAE/_data/imgs/20220826/video_20220826222233_02712.jpg\"\n",
    "#obj.df[ obj.df['imgPath']==s ].index\n",
    "#obj.df.loc[ [31156+i for i in range(-2,2)] ]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(24,4))\n",
    "# plt.plot( obj.df_series['pd_cls'][:300] )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-rhythm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
